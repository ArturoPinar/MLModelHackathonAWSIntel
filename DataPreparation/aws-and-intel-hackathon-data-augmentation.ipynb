{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS and Intel Hackathon for Good: Notebook para Data Augmentation\n",
    "\n",
    "Arturo Pinar\n",
    "\n",
    "Alejandro Pinar\n",
    "\n",
    "Alberto Jiménez\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este notebook es el de aumentar el número de imágenes de cada clase en el dataset. El principal motivo para este aumento se debe a el equilibrado del dataset. \n",
    "\n",
    "Cuando un dataset presenta un número de imágenes muy distinto en cada una de sus clases decimos que es un dataset no equilibrado y puede llevar a que el modelo no se entrene correctamente y no aprenda a generalizar (overfitting). En el caso del dataset utilizado para esta competición el número de imagenes por clase es el siguiente: \n",
    "\n",
    "- Clase 1 = 89 imágenes para test. \n",
    "- Clase 2  = 50 imágenes de test. \n",
    "- Clase 3 = 13 imágenes de test. \n",
    "- Clase 4 = 62 imágenes de test.\n",
    "- Clase 5 = 100 imágenes de test. \n",
    "\n",
    "Como las diferencias son muy grandes entre las distintas clases, además de que para la clase 3 el número de imágenes el claramente insuficiente, este dataset necesita ser aumentado para evitar overfitting en el modelo. \n",
    "\n",
    "Ejecutando cada una de las celdas en orden de este notebook se puede realizar el proceso de augmentation utilizando las transformaciones ofrecidas por Pytorch. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carga de librerías necesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Dependencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será necesario abrir una shell con Anaconda Prompt y lanzar el siguiente comando: \n",
    "\n",
    "``conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uyG2hPIZxGuC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apina\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\apina\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_path_training = \"train/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Configuración del número máximo de imágenes por clase deseado\n",
    "\n",
    "Para cambiar el numero de imagenes basta con cambiar el valor de la variable \"max_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_images = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Loading and Preprocessing\n",
    "## 2.1. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class  1 number of images:  1000\n",
      "class  2 number of images:  1000\n",
      "class  3 number of images:  1000\n",
      "class  4 number of images:  1000\n",
      "class  5 number of images:  1000\n"
     ]
    }
   ],
   "source": [
    "n_images_class = []\n",
    "\n",
    "n_images = 0\n",
    "\n",
    "for i in range(1,6):\n",
    "    class_path = root_path_training + str(i) + \"/\"\n",
    "    img_list = os.listdir(class_path)\n",
    "    \n",
    "    for j in (img_list):\n",
    "      if j[-4:]=='.jpg':\n",
    "        n_images = n_images + 1\n",
    "    n_images_class.append(n_images)\n",
    "    print(\"class \", i, \"number of images: \", str(n_images))\n",
    "    n_images = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000, 1000, 1000, 1000, 1000]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_images_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'RandomResizedCrop':\n",
    "    transforms.Compose([\n",
    "          transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "          transforms.Resize(size=256),\n",
    "          #transforms.ToTensor(),\n",
    "    ]),\n",
    "    'RandomCrop':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomCrop(120, padding = 20),\n",
    "        transforms.Resize(size=256),\n",
    "        #transforms.ToTensor(),\n",
    "    ]),\n",
    "    'RandomRotation':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomRotation(degrees = 15),\n",
    "        transforms.Resize(size=256),\n",
    "        #transforms.ToTensor(),\n",
    "    ]),\n",
    "    \n",
    "    'ColorJitter':\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(brightness = .1, contrast = .1, saturation = .1, hue = .05),\n",
    "        transforms.Resize(size=256),\n",
    "        #transforms.ToTensor(),\n",
    "    ]),\n",
    "    \n",
    "    'RandomHorizontalFlip':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize(size=256),\n",
    "        #transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "random_resized_crop = transform['RandomResizedCrop']\n",
    "random_crop = transform['RandomCrop']\n",
    "random_rotation = transform['RandomRotation']\n",
    "color_jitter = transform['ColorJitter']\n",
    "random_horizontal_flip = transform['RandomHorizontalFlip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder guardar las imagenes aumentadas en la carpeta es necesario crear las subcarpetas de las clases (1 a 5) para poder asociar cada imagen a la clase correcta al cargarlas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "class  1\n",
      "----------------------------\n",
      "Augmenting with  0  images for class  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d745618ef544454a7ad06a7049bd66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images augmented:  0\n",
      "---------------------------\n",
      "class  2\n",
      "----------------------------\n",
      "Augmenting with  6  images for class  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a28f91501b64794afc1b061e708d705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images augmented:  6\n",
      "---------------------------\n",
      "class  3\n",
      "----------------------------\n",
      "Augmenting with  863  images for class  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9964cc568b448f0949e0167b4c2b9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images augmented:  863\n",
      "---------------------------\n",
      "class  4\n",
      "----------------------------\n",
      "Augmenting with  2  images for class  4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5567d7edf1504525a54b0bd5ecd9f003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images augmented:  2\n",
      "---------------------------\n",
      "class  5\n",
      "----------------------------\n",
      "Augmenting with  0  images for class  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf582084c1b48b9a52e3b2859af06dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images augmented:  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "path = \"train/\"\n",
    "\n",
    "\n",
    "images_class = []\n",
    "images_classes = []\n",
    "\n",
    "n_images = 0\n",
    "number_images_augment = 0\n",
    "images_augmented = 0\n",
    "new_img = None\n",
    "\n",
    "for i in range(1,6):\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    print(\"class \", i)\n",
    "    print(\"----------------------------\")\n",
    "    class_path = path + str(i) + \"/\"\n",
    "    img_list = os.listdir(class_path)\n",
    "    number_images_augment = max_images - n_images_class[i - 1]\n",
    "    print(\"Augmenting with \", number_images_augment, \" images for class \", i)\n",
    "    images_augmented = 0\n",
    "    \n",
    "    for images_augmented in tqdm(range(number_images_augment)):\n",
    "        r = random.randint(0, len(img_list) - 1) # Augment a random image\n",
    "        \n",
    "        img = Image.open(path + str(i) + \"/\" + img_list[r]).convert(\"RGB\")\n",
    "        r2 = random.randint(0, 4) # select randomly the transformation for the augmented img\n",
    "            \n",
    "        if r2 == 0:\n",
    "            new_img = random_resized_crop(img)\n",
    "        elif r2 == 1:\n",
    "            new_img = random_crop(img)\n",
    "        elif r2 == 2:\n",
    "            new_img = random_rotation(img)\n",
    "        elif r2 == 3:\n",
    "            new_img = color_jitter(img)\n",
    "        elif r2 == 4:\n",
    "            new_img = random_horizontal_flip(img)\n",
    "                \n",
    "        new_img.save(path + str(i) + \"/\" + \"_augmented_\" + str(images_augmented) + \".jpg\")\n",
    "            \n",
    "            \n",
    "        new_img = None\n",
    "        images_augmented += 1\n",
    "    print(\"images augmented: \", images_augmented)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
