{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS y Intel Hackathon: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install sagemaker-experiments==0.1.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install PyTroch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install torch==1.1.0\n",
    "!{sys.executable} -m pip install torchvision==0.3.0\n",
    "!{sys.executable} -m pip install pillow==6.2.2\n",
    "!{sys.executable} -m pip install --upgrade sagemaker\n",
    "!{sys.executable} -m pip install torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import set_matplotlib_formats, display\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import torch\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torchsummary import summary\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "\n",
    "set_matplotlib_formats(\"retina\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original dataset\n",
    "Run the two cells below to use the original dataset. It should provide good results in training and test although the training process will take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/zhljom0hth586p9/dataset_original.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv dataset_original.zip data/dataset.zip\n",
    "!unzip -quo data/dataset.zip -d data/\n",
    "\n",
    "dataset_path = \"./data/dataset.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Dataset\n",
    "Run the two cells below to use the reduced dataset. It should provide worse results than the original but it will reduce the training process time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/evm0ts2obk7n3cb/dataset_reduced.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv dataset_reduced.zip data/dataset.zip\n",
    "!unzip -quo data/dataset.zip -d data/\n",
    "\n",
    "dataset_path = \"./data/dataset.zip\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset_for_tests\n",
    "Run the two cells below to use a very reduced dataset. It can be used for very fast tests although it will yield to very poor results in the predictions and training accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/zivlm0skt19k3wh/dataset_for_tests.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv dataset_for_tests.zip data/dataset.zip\n",
    "!unzip -quo data/dataset.zip -d data/\n",
    "\n",
    "dataset_path = \"./data/dataset.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload dataset to S3 as zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_sess = sagemaker.Session()\n",
    "sess = sm_sess.boto_session\n",
    "sm = sm_sess.sagemaker_client\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = sess.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "bucket = \"sagemaker-hackathon-demo-{}-{}\".format(sess.region_name, account_id)\n",
    "prefix = \"hackathon\"\n",
    "\n",
    "try:\n",
    "    if sess.region_name == \"us-east-1\":\n",
    "        sess.client(\"s3\").create_bucket(Bucket=bucket)\n",
    "    else:\n",
    "        sess.client(\"s3\").create_bucket(\n",
    "            Bucket=bucket, CreateBucketConfiguration={\"LocationConstraint\": sess.region_name}\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource(\"s3\", region_name = sess.region_name)\n",
    "\n",
    "inputs = None\n",
    "\n",
    "try:\n",
    "\n",
    "    \n",
    "    inputs = sagemaker.Session().upload_data(path=dataset_path, bucket=bucket, key_prefix=prefix)\n",
    "    print(\"input spec: {}\".format(inputs))\n",
    "except Exception as exp:\n",
    "    print(\"exp: \", exp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m#import sagemaker_containers\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdist\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, transforms\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mzipfile\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DataLoader\n",
      "\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "logger.setLevel(logging.DEBUG)\n",
      "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
      "\n",
      "img_transform= {\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mdataset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    transforms.Compose([\n",
      "        transforms.Resize((\u001b[34m28\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m)), \n",
      "        transforms.ToTensor(),\n",
      "    ]),\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtraining\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    transforms.Compose([\n",
      "         transforms.RandomResizedCrop(size=\u001b[34m224\u001b[39;49;00m),\n",
      "         transforms.RandomHorizontalFlip(),\n",
      "    ]),\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \n",
      "    transforms.Compose([\n",
      "        transforms.Resize(size=\u001b[34m224\u001b[39;49;00m),\n",
      "    ]),\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtesting\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \n",
      "    transforms.Compose([\n",
      "        transforms.Resize((\u001b[34m32\u001b[39;49;00m, \u001b[34m32\u001b[39;49;00m)),\n",
      "        transforms.ToTensor(),\n",
      "    ]),\n",
      "}\n",
      "\n",
      "\u001b[37m# Based on https://github.com/pytorch/examples/blob/master/mnist/main.py\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mNet\u001b[39;49;00m(nn.Module):\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[36msuper\u001b[39;49;00m(Net, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\n",
      "        \u001b[36mself\u001b[39;49;00m.conv1 = nn.Conv2d(\u001b[34m3\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m, kernel_size=\u001b[34m5\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2 = nn.Conv2d(\u001b[34m10\u001b[39;49;00m, \u001b[34m20\u001b[39;49;00m, kernel_size=\u001b[34m5\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2_drop = nn.Dropout2d()\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(\u001b[34m320\u001b[39;49;00m, \u001b[34m50\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(\u001b[34m50\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\n",
      "        x = F.relu(F.max_pool2d(\u001b[36mself\u001b[39;49;00m.conv1(x), \u001b[34m2\u001b[39;49;00m))\n",
      "        x = F.relu(F.max_pool2d(\u001b[36mself\u001b[39;49;00m.conv2_drop(\u001b[36mself\u001b[39;49;00m.conv2(x)), \u001b[34m2\u001b[39;49;00m))\n",
      "        x = x.view(-\u001b[34m1\u001b[39;49;00m, \u001b[34m320\u001b[39;49;00m)\n",
      "        x = F.relu(\u001b[36mself\u001b[39;49;00m.fc1(x))\n",
      "        x = F.dropout(x, training=\u001b[36mself\u001b[39;49;00m.training)\n",
      "        x = \u001b[36mself\u001b[39;49;00m.fc2(x)\n",
      "        \u001b[34mreturn\u001b[39;49;00m F.log_softmax(x, dim=\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcheck_dataset_loaded\u001b[39;49;00m():\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m-------------------------\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mcheck_dataset_loaded\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m-------------------------\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    result = []\n",
      "    found = \u001b[34mFalse\u001b[39;49;00m\n",
      "    cwd = os.getcwd()\n",
      "    \u001b[34mfor\u001b[39;49;00m root, dirr, files \u001b[35min\u001b[39;49;00m os.walk(cwd):\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mdataset.zip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[35min\u001b[39;49;00m files:\n",
      "            found = \u001b[34mTrue\u001b[39;49;00m\n",
      "            \u001b[34mbreak\u001b[39;49;00m\n",
      "            \n",
      "    \u001b[34mreturn\u001b[39;49;00m found\n",
      "    \n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mload_dataset\u001b[39;49;00m():\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m-------------------------\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mload_dataset\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m-------------------------\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m (check_dataset_loaded() == \u001b[34mFalse\u001b[39;49;00m):\n",
      "        cwd = os.getcwd()\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m----------------------------\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mcurrent dir: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, cwd)\n",
      "        s3_client = boto3.client(\u001b[33m\"\u001b[39;49;00m\u001b[33ms3\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        bucket = \u001b[33m\"\u001b[39;49;00m\u001b[33msagemaker-hackathon-demo-eu-west-1-017233837209\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "        s3_client.download_file(\n",
      "        bucket,\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mhackathon/dataset.zip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mdataset.zip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        )\n",
      "        \n",
      "        \n",
      "        \u001b[34mwith\u001b[39;49;00m zipfile.ZipFile(\u001b[33m\"\u001b[39;49;00m\u001b[33m./dataset.zip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m zip_ref:\n",
      "            zip_ref.extractall(\u001b[33m\"\u001b[39;49;00m\u001b[33m./\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m-------------------------\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mafter zip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_train_data_loader\u001b[39;49;00m(batch_size, training_dir, is_distributed, **kwargs):\n",
      "\u001b[37m#     logger.info(\"Get train data loader\")\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m-------------------------\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m_get_train_data_loader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m-------------------------\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    load_dataset()\n",
      "    train_dataset = datasets.ImageFolder(\u001b[33m\"\u001b[39;49;00m\u001b[33m./final_dataset/train/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, transform=img_transform[\u001b[33m'\u001b[39;49;00m\u001b[33mdataset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    train_sampler = (\n",
      "        torch.utils.data.distributed.DistributedSampler(train_dataset) \u001b[34mif\u001b[39;49;00m is_distributed \u001b[34melse\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\n",
      "    )\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(\n",
      "        train_dataset,\n",
      "        batch_size=batch_size,\n",
      "        shuffle=train_sampler \u001b[35mis\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m,\n",
      "        sampler=train_sampler,\n",
      "        **kwargs)\n",
      "\n",
      "\n",
      "\u001b[37m# def _get_train_data_loader(batch_size, training_dir, is_distributed, **kwargs):\u001b[39;49;00m\n",
      "\u001b[37m#     logger.info(\"Get train data loader\")\u001b[39;49;00m\n",
      "\u001b[37m#     dataset = datasets.MNIST(\u001b[39;49;00m\n",
      "\u001b[37m#         training_dir,\u001b[39;49;00m\n",
      "\u001b[37m#         train=True,\u001b[39;49;00m\n",
      "\u001b[37m#         transform=transforms.Compose(\u001b[39;49;00m\n",
      "\u001b[37m#             [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\u001b[39;49;00m\n",
      "\u001b[37m#         ),\u001b[39;49;00m\n",
      "\u001b[37m#     )\u001b[39;49;00m\n",
      "    \n",
      "\u001b[37m#     print(\"TYPE DATASET MNIST --------------\")\u001b[39;49;00m\n",
      "\u001b[37m#     print(type(dataset))\u001b[39;49;00m\n",
      "\u001b[37m#     train_sampler = (\u001b[39;49;00m\n",
      "\u001b[37m#         torch.utils.data.distributed.DistributedSampler(dataset) if is_distributed else None\u001b[39;49;00m\n",
      "\u001b[37m#     )\u001b[39;49;00m\n",
      "\u001b[37m#     return torch.utils.data.DataLoader(\u001b[39;49;00m\n",
      "\u001b[37m#         dataset,\u001b[39;49;00m\n",
      "\u001b[37m#         batch_size=batch_size,\u001b[39;49;00m\n",
      "\u001b[37m#         shuffle=train_sampler is None,\u001b[39;49;00m\n",
      "\u001b[37m#         sampler=train_sampler,\u001b[39;49;00m\n",
      "\u001b[37m#         **kwargs\u001b[39;49;00m\n",
      "\u001b[37m#     )\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_test_data_loader\u001b[39;49;00m(batch_size, training_dir, **kwargs):\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet test data loader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m-------------------------\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m_get_test_data_loader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m-------------------------\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    load_dataset()\n",
      "    test_dataset = datasets.ImageFolder(\u001b[33m\"\u001b[39;49;00m\u001b[33m./final_dataset/GT/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, transform=img_transform[\u001b[33m'\u001b[39;49;00m\u001b[33mdataset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(\n",
      "        test_dataset,\n",
      "        batch_size=batch_size,\n",
      "        shuffle=\u001b[34mTrue\u001b[39;49;00m,\n",
      "        **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[37m# def _get_test_data_loader(test_batch_size, training_dir, **kwargs):\u001b[39;49;00m\n",
      "\u001b[37m#     logger.info(\"Get test data loader\")\u001b[39;49;00m\n",
      "\u001b[37m#     return torch.utils.data.DataLoader(\u001b[39;49;00m\n",
      "\u001b[37m#         datasets.MNIST(\u001b[39;49;00m\n",
      "\u001b[37m#             training_dir,\u001b[39;49;00m\n",
      "\u001b[37m#             train=False,\u001b[39;49;00m\n",
      "\u001b[37m#             transform=transforms.Compose(\u001b[39;49;00m\n",
      "\u001b[37m#                 [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\u001b[39;49;00m\n",
      "\u001b[37m#             ),\u001b[39;49;00m\n",
      "\u001b[37m#         ),\u001b[39;49;00m\n",
      "\u001b[37m#         batch_size=test_batch_size,\u001b[39;49;00m\n",
      "\u001b[37m#         shuffle=True,\u001b[39;49;00m\n",
      "\u001b[37m#         **kwargs\u001b[39;49;00m\n",
      "\u001b[37m#     )\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_average_gradients\u001b[39;49;00m(model):\n",
      "    \u001b[37m# Gradient averaging.\u001b[39;49;00m\n",
      "    size = \u001b[36mfloat\u001b[39;49;00m(dist.get_world_size())\n",
      "    \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m model.parameters():\n",
      "        dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM)\n",
      "        param.grad.data /= size\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(args):\n",
      "    is_distributed = \u001b[36mlen\u001b[39;49;00m(args.hosts) > \u001b[34m1\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m args.backend \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mDistributed training - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(is_distributed))\n",
      "    use_cuda = args.num_gpus > \u001b[34m0\u001b[39;49;00m\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mNumber of gpus available - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(args.num_gpus))\n",
      "    kwargs = {\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_workers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34m1\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpin_memory\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34mTrue\u001b[39;49;00m} \u001b[34mif\u001b[39;49;00m use_cuda \u001b[34melse\u001b[39;49;00m {}\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m use_cuda \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed:\n",
      "        \u001b[37m# Initialize the distributed environment.\u001b[39;49;00m\n",
      "        world_size = \u001b[36mlen\u001b[39;49;00m(args.hosts)\n",
      "        os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mWORLD_SIZE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[36mstr\u001b[39;49;00m(world_size)\n",
      "        host_rank = args.hosts.index(args.current_host)\n",
      "        os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mRANK\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[36mstr\u001b[39;49;00m(host_rank)\n",
      "        dist.init_process_group(backend=args.backend, rank=host_rank, world_size=world_size)\n",
      "        logger.info(\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mInitialized the distributed environment: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m backend on \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m nodes. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "                args.backend, dist.get_world_size()\n",
      "            )\n",
      "            + \u001b[33m\"\u001b[39;49;00m\u001b[33mCurrent host rank is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m. Number of gpus: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(dist.get_rank(), args.num_gpus)\n",
      "        )\n",
      "\n",
      "    \u001b[37m# set the seed for generating random numbers\u001b[39;49;00m\n",
      "    torch.manual_seed(args.seed)\n",
      "    \u001b[34mif\u001b[39;49;00m use_cuda:\n",
      "        torch.cuda.manual_seed(args.seed)\n",
      "\n",
      "    train_loader = _get_train_data_loader(args.batch_size, args.data_dir, is_distributed, **kwargs)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m********* PASO TRAIN ****************!!!!!!! \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    test_loader = _get_test_data_loader(args.test_batch_size, args.data_dir, **kwargs)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m********* PASO TEST ****************!!!!!!! \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    logger.debug(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mProcesses \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m) of train data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "            \u001b[36mlen\u001b[39;49;00m(train_loader.sampler),\n",
      "            \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\n",
      "            \u001b[34m100.0\u001b[39;49;00m * \u001b[36mlen\u001b[39;49;00m(train_loader.sampler) / \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\n",
      "        )\n",
      "    )\n",
      "\n",
      "    logger.debug(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mProcesses \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m) of test data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "            \u001b[36mlen\u001b[39;49;00m(test_loader.sampler),\n",
      "            \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\n",
      "            \u001b[34m100.0\u001b[39;49;00m * \u001b[36mlen\u001b[39;49;00m(test_loader.sampler) / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\n",
      "        )\n",
      "    )\n",
      "\n",
      "    model = Net().to(device)\n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed \u001b[35mand\u001b[39;49;00m use_cuda:\n",
      "        \u001b[37m# multi-machine multi-gpu case\u001b[39;49;00m\n",
      "        model = torch.nn.parallel.DistributedDataParallel(model)\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[37m# single-machine multi-gpu case or single-machine or multi-machine cpu case\u001b[39;49;00m\n",
      "        model = torch.nn.DataParallel(model)\n",
      "\n",
      "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, args.epochs + \u001b[34m1\u001b[39;49;00m):\n",
      "        model.train()\n",
      "        \u001b[34mfor\u001b[39;49;00m batch_idx, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader, \u001b[34m1\u001b[39;49;00m):\n",
      "            data, target = data.to(device), target.to(device)\n",
      "            optimizer.zero_grad()\n",
      "            output = model(data)\n",
      "            loss = F.nll_loss(output, target)\n",
      "            loss.backward()\n",
      "            \u001b[34mif\u001b[39;49;00m is_distributed \u001b[35mand\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m use_cuda:\n",
      "                \u001b[37m# average gradients manually for multi-machine cpu case only\u001b[39;49;00m\n",
      "                _average_gradients(model)\n",
      "            optimizer.step()\n",
      "\u001b[37m#             if batch_idx % args.log_interval == 0:\u001b[39;49;00m\n",
      "            logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mTrain Epoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m [\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)] Loss: \u001b[39;49;00m\u001b[33m{:.6f}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch,batch_idx * \u001b[36mlen\u001b[39;49;00m(data),\u001b[36mlen\u001b[39;49;00m(train_loader.sampler),\u001b[34m100.0\u001b[39;49;00m * batch_idx / \u001b[36mlen\u001b[39;49;00m(train_loader),loss.item(),))\n",
      "        test(model, test_loader, device)\n",
      "    save_model(model, args.model_dir)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtest\u001b[39;49;00m(model, test_loader, device):\n",
      "    model.eval()\n",
      "    test_loss = \u001b[34m0\u001b[39;49;00m\n",
      "    correct = \u001b[34m0\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "        \u001b[34mfor\u001b[39;49;00m data, target \u001b[35min\u001b[39;49;00m test_loader:\n",
      "            data, target = data.to(device), target.to(device)\n",
      "            output = model(data)\n",
      "            test_loss += F.nll_loss(output, target, size_average=\u001b[34mFalse\u001b[39;49;00m).item()  \u001b[37m# sum up batch loss\u001b[39;49;00m\n",
      "            pred = output.max(\u001b[34m1\u001b[39;49;00m, keepdim=\u001b[34mTrue\u001b[39;49;00m)[\u001b[34m1\u001b[39;49;00m]  \u001b[37m# get the index of the max log-probability\u001b[39;49;00m\n",
      "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
      "\n",
      "    test_loss /= \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)\n",
      "    logger.info(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mTest set: Average loss: \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m, Accuracy: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "            test_loss, correct, \u001b[36mlen\u001b[39;49;00m(test_loader.dataset), \u001b[34m100.0\u001b[39;49;00m * correct / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)\n",
      "        )\n",
      "    )\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    model = torch.nn.DataParallel(Net())\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model.load_state_dict(torch.load(f))\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(model, model_dir):\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    path = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[37m# recommended way from http://pytorch.org/docs/master/notes/serialization.html\u001b[39;49;00m\n",
      "    torch.save(model.cpu().state_dict(), path)\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Data and model checkpoints directories\u001b[39;49;00m\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m64\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33minput batch size for training (default: 64)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--test-batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m1000\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33minput batch size for testing (default: 1000)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m10\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.01\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mlearning rate (default: 0.01)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.5\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mSGD momentum (default: 0.5)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    )\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--log-interval\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m100\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mhow many batches to wait before logging training status\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--backend\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "        default=\u001b[34mNone\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mbackend for distributed training (tcp, gloo on cpu and gloo, nccl on gpu)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "\n",
      "    \u001b[37m# Container environment\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]))\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "\n",
      "    train(parser.parse_args())\n"
     ]
    }
   ],
   "source": [
    "!pygmentize model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"model.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.4.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_count=2,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    hyperparameters={\"epochs\": 6, \"backend\": \"gloo\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 14:25:51 Starting - Starting the training job...\n",
      "2022-04-20 14:26:17 Starting - Preparing the instances for trainingProfilerReport-1650464751: InProgress\n",
      ".........\n",
      "2022-04-20 14:27:45 Downloading - Downloading input data...\n",
      "2022-04-20 14:28:19 Training - Downloading the training image......\n",
      "2022-04-20 14:29:20 Training - Training image download completed. Training in progress..\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2022-04-20 14:29:24,821 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2022-04-20 14:29:24,825 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-04-20 14:29:24,842 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2022-04-20 14:29:24,851 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2022-04-20 14:29:25,377 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2022-04-20 14:29:25,377 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2022-04-20 14:29:25,377 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2022-04-20 14:29:25,378 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.6 -m pip install . \u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-04-20 14:29:23,804 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-04-20 14:29:23,807 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-04-20 14:29:23,823 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-04-20 14:29:23,828 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-04-20 14:29:24,204 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2022-04-20 14:29:24,204 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2022-04-20 14:29:24,204 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2022-04-20 14:29:24,205 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmp9zfsqaof/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=9970 sha256=03e17b21c7fd0da1334e93339b2b4cffe836be958b3aad44295833d80a54ae23\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-c1dch964/wheels/5b/91/cc/4acaa8d57dc17076275545d4f974c4603e570628edf2cd1c7c\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[35mProcessing /tmp/tmp70h_qa5q/module_dir\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=9970 sha256=ac7ed8a444478f3ad2fc87901d90430c0eb460c5a80a2b74d3afd2ce52551af6\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-w5pocc3x/wheels/64/70/09/a3ad73ff969505a0f6774b8bc0568856eba12d2d04f735ae0d\u001b[0m\n",
      "\u001b[35mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34m2022-04-20 14:29:27,611 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-04-20 14:29:27,635 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-04-20 14:29:27,654 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-04-20 14:29:27,668 sagemaker-containers INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 6\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-04-20-14-25-51-446\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-017233837209/pytorch-training-2022-04-20-14-25-51-446/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-2\",\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":6}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-017233837209/pytorch-training-2022-04-20-14-25-51-446/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":6},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-04-20-14-25-51-446\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-017233837209/pytorch-training-2022-04-20-14-25-51-446/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"6\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=6\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 mnist.py --backend gloo --epochs 6\u001b[0m\n",
      "\u001b[35mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[35mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[35m2022-04-20 14:29:29,622 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-04-20 14:29:29,648 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-04-20 14:29:29,669 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-04-20 14:29:29,682 sagemaker-containers INFO     Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 6\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"pytorch-training-2022-04-20-14-25-51-446\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-017233837209/pytorch-training-2022-04-20-14-25-51-446/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-2\",\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"backend\":\"gloo\",\"epochs\":6}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-eu-west-1-017233837209/pytorch-training-2022-04-20-14-25-51-446/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":6},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"pytorch-training-2022-04-20-14-25-51-446\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-017233837209/pytorch-training-2022-04-20-14-25-51-446/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"6\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=6\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.6 mnist.py --backend gloo --epochs 6\u001b[0m\n",
      "\u001b[35mDistributed training - True\u001b[0m\n",
      "\u001b[35mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[35mInitialized the distributed environment: 'gloo' backend on 2 nodes. Current host rank is 1. Number of gpus: 0\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35m_get_train_data_loader\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35mload_dataset\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35mcheck_dataset_loaded\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35m----------------------------\u001b[0m\n",
      "\u001b[35mcurrent dir:  /opt/ml/code\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35mafter zip\u001b[0m\n",
      "\u001b[35m********* PASO TRAIN ****************!!!!!!! \u001b[0m\n",
      "\u001b[35mGet test data loader\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35m_get_test_data_loader\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35mload_dataset\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35mcheck_dataset_loaded\u001b[0m\n",
      "\u001b[35m-------------------------\u001b[0m\n",
      "\u001b[35m********* PASO TEST ****************!!!!!!! \u001b[0m\n",
      "\u001b[35mProcesses 40/80 (50%) of train data\u001b[0m\n",
      "\u001b[35mProcesses 65/65 (100%) of test data\u001b[0m\n",
      "\u001b[34mDistributed training - True\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mInitialized the distributed environment: 'gloo' backend on 2 nodes. Current host rank is 0. Number of gpus: 0\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34m_get_train_data_loader\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34mload_dataset\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34mcheck_dataset_loaded\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34m----------------------------\u001b[0m\n",
      "\u001b[34mcurrent dir:  /opt/ml/code\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34mafter zip\u001b[0m\n",
      "\u001b[34m********* PASO TRAIN ****************!!!!!!! \u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34m_get_test_data_loader\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34mload_dataset\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34mcheck_dataset_loaded\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34m********* PASO TEST ****************!!!!!!! \u001b[0m\n",
      "\u001b[34mProcesses 40/80 (50%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 65/65 (100%) of test data\u001b[0m\n",
      "\u001b[35m[2022-04-20 14:29:43.438 algo-2:46 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2022-04-20 14:29:43.438 algo-2:46 INFO hook.py:192] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[35m[2022-04-20 14:29:43.439 algo-2:46 INFO hook.py:237] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[35m[2022-04-20 14:29:43.439 algo-2:46 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[35m[2022-04-20 14:29:43.439 algo-2:46 INFO hook.py:382] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-04-20 14:29:53.530 algo-1:46 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-04-20 14:29:53.530 algo-1:46 INFO hook.py:192] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-04-20 14:29:53.531 algo-1:46 INFO hook.py:237] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-04-20 14:29:53.531 algo-1:46 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-04-20 14:29:53.531 algo-1:46 INFO hook.py:382] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [40/40 (100%)] Loss: 2.326729\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [40/40 (100%)] Loss: 2.319361\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 2.3173, Accuracy: 12/65 (18%)\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 2.3173, Accuracy: 12/65 (18%)\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [40/40 (100%)] Loss: 2.320292\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [40/40 (100%)] Loss: 2.311602\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 2.3146, Accuracy: 13/65 (20%)\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 2.3146, Accuracy: 13/65 (20%)\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [40/40 (100%)] Loss: 2.319909\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [40/40 (100%)] Loss: 2.317999\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 2.3113, Accuracy: 13/65 (20%)\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 2.3113, Accuracy: 13/65 (20%)\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [40/40 (100%)] Loss: 2.317224\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [40/40 (100%)] Loss: 2.316314\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 2.3079, Accuracy: 13/65 (20%)\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 2.3079, Accuracy: 13/65 (20%)\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [40/40 (100%)] Loss: 2.307126\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [40/40 (100%)] Loss: 2.311327\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 2.3042, Accuracy: 13/65 (20%)\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 2.3042, Accuracy: 13/65 (20%)\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [40/40 (100%)] Loss: 2.305017\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [40/40 (100%)] Loss: 2.296201\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 2.3002, Accuracy: 13/65 (20%)\u001b[0m\n",
      "\u001b[35mSaving the model.\u001b[0m\n",
      "\u001b[35m2022-04-20 14:32:01,232 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 2.3002, Accuracy: 13/65 (20%)\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2022-04-20 14:32:01,269 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-04-20 14:32:27 Uploading - Uploading generated training model\n",
      "2022-04-20 14:32:27 Completed - Training job completed\n",
      "ProfilerReport-1650464751: NoIssuesFound\n",
      "Training seconds: 546\n",
      "Billable seconds: 546\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"training\": inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-017233837209/pytorch-training-2022-04-20-14-25-51-446/output/model.tar.gz'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-017233837209/pytorch-training-2022-04-20-14-25-51-446/output/model.tar.gz'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a folder to save model trained model, and download the model.tar.gz file to local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-017233837209/pytorch-training-2022-04-20-14-25-51-446/output/model.tar.gz to model/model.tar.gz\n",
      "model.pth\n",
      "model.pth\n"
     ]
    }
   ],
   "source": [
    "%%sh -s $estimator.model_data\n",
    "mkdir model\n",
    "aws s3 cp $1 model/ \n",
    "tar xvzf model/model.tar.gz --directory ./model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert your model into the TorchScript format using torch.jit.trace or torch.jit.script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model_loaded = torch.load(\"model/model.pth\")\n",
    "model = Net().to(\"cpu\")\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.load_state_dict(model_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "trace_input = torch.rand(1, 3, 28, 28)\n",
    "traced_model = torch.jit.trace(model.eval(), trace_input)\n",
    "\n",
    "torch.jit.save(traced_model, \"model.pth\")\n",
    "subprocess.call([\"tar\", \"-czvf\", \"traced_hackathon_model.tar.gz\", \"model.pth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\n",
      "\u001b[37m# language governing permissions and limitations under the License.\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m absolute_import\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "logger.setLevel(logging.DEBUG)\n",
      "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
      "\n",
      "\u001b[37m# To use new EIA inference API, customer should use attach_eia(model, eia_ordinal_number)\u001b[39;49;00m\n",
      "VERSIONS_USE_NEW_API = [\u001b[33m\"\u001b[39;49;00m\u001b[33m1.5.1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, model):\n",
      "    logger.info(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mPerforming EIA inference with Torch JIT context with input of size \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "            input_data.shape\n",
      "        )\n",
      "    )\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m model.forward(input_data)\n",
      "\u001b[37m#     # With EI, client instance should be CPU for cost-efficiency. Subgraphs with unsupported arguments run locally. Server runs with CUDA\u001b[39;49;00m\n",
      "\u001b[37m#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[39;49;00m\n",
      "\u001b[37m#     input_data = input_data.to(device)\u001b[39;49;00m\n",
      "\u001b[37m#     # Please make sure model is loaded to cpu and has been eval(), in this example, we have done this step in model_fn()\u001b[39;49;00m\n",
      "\u001b[37m#     with torch.no_grad():\u001b[39;49;00m\n",
      "\u001b[37m#         if torch.__version__ in VERSIONS_USE_NEW_API:\u001b[39;49;00m\n",
      "\u001b[37m#             # Please make sure torcheia has been imported\u001b[39;49;00m\n",
      "\u001b[37m#             import torcheia\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m#             # We need to set the profiling executor for EIA\u001b[39;49;00m\n",
      "\u001b[37m#             torch._C._jit_set_profiling_executor(False)\u001b[39;49;00m\n",
      "\u001b[37m#             with torch.jit.optimized_execution(True):\u001b[39;49;00m\n",
      "\u001b[37m#                 return model.forward(input_data)\u001b[39;49;00m\n",
      "\u001b[37m#         # Set the target device to the accelerator ordinal\u001b[39;49;00m\n",
      "\u001b[37m#         else:\u001b[39;49;00m\n",
      "\u001b[37m#             with torch.jit.optimized_execution(True, {\"target_device\": \"eia:0\"}):\u001b[39;49;00m\n",
      "\u001b[37m#                 return model(input_data)\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    \u001b[34mtry\u001b[39;49;00m:\n",
      "        loaded_model = torch.jit.load(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, map_location=torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "        \u001b[34mif\u001b[39;49;00m torch.__version__ \u001b[35min\u001b[39;49;00m VERSIONS_USE_NEW_API:\n",
      "            \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorcheia\u001b[39;49;00m\n",
      "\n",
      "            loaded_model = loaded_model.eval()\n",
      "            loaded_model = torcheia.jit.attach_eia(loaded_model, \u001b[34m0\u001b[39;49;00m)\n",
      "        \u001b[34mreturn\u001b[39;49;00m loaded_model\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "        logger.exception(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mException in model fn \u001b[39;49;00m\u001b[33m{\u001b[39;49;00me\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize deploy_ei.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "from datetime import datetime\n",
    "\n",
    "instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "# TorchScript model\n",
    "tar_filename = \"traced_hackathon_model.tar.gz\"\n",
    "\n",
    "# You can also upload model artifacts to S3\n",
    "# print('Upload tarball to S3')\n",
    "# model_data = sagemaker_session.upload_data(path=tar_filename, bucket=bucket, key_prefix=prefix)\n",
    "model_data = tar_filename\n",
    "\n",
    "endpoint_name = (\"hackathon-ei-traced\").replace(\".\", \"\").replace(\"_\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    entry_point=\"deploy_ei.py\",\n",
    "    framework_version=\"1.3.1\",\n",
    "    py_version=\"py3\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "# Attach EI remotely\n",
    "\n",
    "# Function will exit before endpoint is finished creating\n",
    "predictor = pytorch.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    wait=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_resized (28, 28, 3)\n",
      "x shape torch.Size([1, 3, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import Pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "convert = torchvision.transforms.ToTensor()\n",
    "\n",
    "file = \"./aws.png\"\n",
    "# test_image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "test_image = cv2.imread(file)\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "\n",
    "img_resized = cv2.resize(test_image, (28, 28), interpolation=cv2.INTER_LINEAR)\n",
    "img_resized = cv2.bitwise_not(img_resized)\n",
    "print(\"img_resized\", img_resized.shape)\n",
    "\n",
    "## Get our input image as a tensor. We add a dimension with \"unsqueeze\", because\n",
    "## PyTorch is used to working with batches.\n",
    "x = convert(img_resized).unsqueeze(0)\n",
    "\n",
    "print(\"x shape\", x.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response [[-2.27607346 -2.33181691 -2.42464399 -2.27142167 -2.198632   -2.37246609\n",
      "  -2.32089543 -2.27894354 -2.29596758 -2.27232647]]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# im_ = np.random.rand(1, 1, 28, 28)\n",
    "\n",
    "# image = np.array(im_, dtype=np.float32)\n",
    "response = predictor.predict(x)\n",
    "print(\"response\", response)\n",
    "prediction = response.argmax(axis=1)[0]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
